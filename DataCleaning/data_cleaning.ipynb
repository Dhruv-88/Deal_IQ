{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/dhruvpatel/Desktop/projects/DealPredection/data/vehicles.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaning import drop_unnecessary_columns , drop_rows_with_few_missing_values\n",
    "\n",
    "df, sumaary = drop_unnecessary_columns(df) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows due to NAs \n",
    "\n",
    "df, summary = df_cleaned, summary = drop_rows_with_few_missing_values(df) \n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values in title status with 'missing' \n",
    "from data_title_status import fill_missing_values \n",
    "\n",
    "df,summary = fill_missing_values(df) \n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_transmission import fill_missing_values_transmission\n",
    "\n",
    "df,summary = fill_missing_values_transmission(df) \n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  standardization  and extracting info from model and description.\n",
    "from model_extract import process_car_dataset\n",
    "\n",
    "featured_eng=process_car_dataset(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null values reduced \n",
    "featured_eng.isnull().sum() - df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the rows where manufacturer is null \n",
    "\n",
    "featured_eng = featured_eng[featured_eng['manufacturer'].notna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drive column cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardasition \n",
    "from drive_cleaning import process_drive_column\n",
    "featured_eng=process_drive_column(featured_eng, 'drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values from research : (na values)\n",
    "from drive_cleaning import fill_missing_drive_from_reference\n",
    "\n",
    "\n",
    "featured_eng = fill_missing_drive_from_reference(featured_eng,\n",
    "                                                 reference_file='/Users/dhruvpatel/Desktop/projects/DealPredection/data/models_with_drive.csv'\n",
    "                                                 )\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_eng['drive'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Model \n",
    "\n",
    "Clean in stages:\n",
    "* Stage 1: Remove obvious junk (numbers, too short, too long)\n",
    "* Stage 2: Extract core model from complex strings\n",
    "* Stage 3: Standardize spelling and format\n",
    "* Stage 4: Apply manufacturer-specific rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 : Remove obvious junk (numbers, too short, too long)\n",
    "\n",
    "from model_cleaning import remove_numerical_models\n",
    "\n",
    "featured_eng=remove_numerical_models(featured_eng)\n",
    "\n",
    "featured_eng['model'].value_counts().to_csv('model_counts.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage 2 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_eng['manufacturer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featured_eng.to_csv('cleaned_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# featured_eng = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_eng['model'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_cleaning import clean_models_with_list\n",
    " \n",
    "featured_eng_new = clean_models_with_list(featured_eng) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_eng_new['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_eng_new.to_csv('clean_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>region</th>\n",
       "      <th>region_url</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>description</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>cylinders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>7316814884</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>33590</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>gmc</td>\n",
       "      <td>Sierra</td>\n",
       "      <td>gas</td>\n",
       "      <td>57923.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>white</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.590</td>\n",
       "      <td>-85.4800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>7316814758</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>22590</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>silverado</td>\n",
       "      <td>gas</td>\n",
       "      <td>71229.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>blue</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.590</td>\n",
       "      <td>-85.4800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>7316814989</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>39590</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>silverado</td>\n",
       "      <td>gas</td>\n",
       "      <td>19160.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>red</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.590</td>\n",
       "      <td>-85.4800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>7316743432</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>30990</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>toyota</td>\n",
       "      <td>Tundra</td>\n",
       "      <td>gas</td>\n",
       "      <td>41124.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>red</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.590</td>\n",
       "      <td>-85.4800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>7316356412</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>15000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>F-150</td>\n",
       "      <td>gas</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rwd</td>\n",
       "      <td>truck</td>\n",
       "      <td>black</td>\n",
       "      <td>2013 F-150 XLT V6 4 Door. Good condition. Leve...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.592</td>\n",
       "      <td>-85.5189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          id  region                     region_url  price  \\\n",
       "0          27  7316814884  auburn  https://auburn.craigslist.org  33590   \n",
       "1          28  7316814758  auburn  https://auburn.craigslist.org  22590   \n",
       "2          29  7316814989  auburn  https://auburn.craigslist.org  39590   \n",
       "3          30  7316743432  auburn  https://auburn.craigslist.org  30990   \n",
       "4          31  7316356412  auburn  https://auburn.craigslist.org  15000   \n",
       "\n",
       "     year manufacturer      model fuel  odometer title_status transmission  \\\n",
       "0  2014.0          gmc     Sierra  gas   57923.0        clean        other   \n",
       "1  2010.0    chevrolet  silverado  gas   71229.0        clean        other   \n",
       "2  2020.0    chevrolet  silverado  gas   19160.0        clean        other   \n",
       "3  2017.0       toyota     Tundra  gas   41124.0        clean        other   \n",
       "4  2013.0         ford      F-150  gas  128000.0        clean    automatic   \n",
       "\n",
       "  drive    type paint_color  \\\n",
       "0   4wd  pickup       white   \n",
       "1   4wd  pickup        blue   \n",
       "2   4wd  pickup         red   \n",
       "3   4wd  pickup         red   \n",
       "4   rwd   truck       black   \n",
       "\n",
       "                                         description state     lat     long  \\\n",
       "0  Carvana is the safer way to buy a car During t...    al  32.590 -85.4800   \n",
       "1  Carvana is the safer way to buy a car During t...    al  32.590 -85.4800   \n",
       "2  Carvana is the safer way to buy a car During t...    al  32.590 -85.4800   \n",
       "3  Carvana is the safer way to buy a car During t...    al  32.590 -85.4800   \n",
       "4  2013 F-150 XLT V6 4 Door. Good condition. Leve...    al  32.592 -85.5189   \n",
       "\n",
       "  cylinders  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "clean_df =pd.read_csv('clean_v1.csv')\n",
    "clean_df.head()\n",
    "\n",
    "# clean_df = featured_eng_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "id                   0\n",
       "region               0\n",
       "region_url           0\n",
       "price                0\n",
       "year                 0\n",
       "manufacturer         0\n",
       "model                0\n",
       "fuel                 0\n",
       "odometer             0\n",
       "title_status         0\n",
       "transmission         0\n",
       "drive            37445\n",
       "type             45575\n",
       "paint_color     117330\n",
       "description          0\n",
       "state                0\n",
       "lat                  0\n",
       "long                 0\n",
       "cylinders       303273\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive missing value impute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppign columns where drive ad type both is null \n",
    "clean_df = clean_df.dropna(subset=['drive', 'type'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "sedan          86026\n",
       "SUV            80463\n",
       "truck          43415\n",
       "pickup         40589\n",
       "coupe          19572\n",
       "other          19074\n",
       "hatchback      16781\n",
       "van            11252\n",
       "wagon          11241\n",
       "convertible     8368\n",
       "mini-van        4917\n",
       "bus              720\n",
       "offroad          714\n",
       "mini van         187\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['type'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_rows': 371992,\n",
       " 'rows_changed': np.int64(5104),\n",
       " 'replacements': {'mini van': 'minivan', 'mini-van': 'minivan'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning and standardasition  (type) \n",
    "from data_type import replace_values \n",
    "clean_df, summary =replace_values(clean_df, 'type', {'mini van': 'minivan', 'mini-van': 'minivan'})\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_rows': 371992,\n",
       " 'missing_before': np.int64(28673),\n",
       " 'missing_after': np.int64(258),\n",
       " 'values_filled': np.int64(28415),\n",
       " 'mapping_created': 4559}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling null values based on data present. \n",
    "# First, let's see what we're working with\n",
    "\n",
    "from data_type import fill_type_from_model\n",
    "\n",
    "df_clean, summary = fill_type_from_model(clean_df)\n",
    "\n",
    "summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_rows': 371992,\n",
       " 'missing_before': np.int64(20543),\n",
       " 'missing_after': np.int64(0),\n",
       " 'values_imputed': np.int64(20543)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute drive 1 ( based on cross tab type )\n",
    "\n",
    "from data_drive import impute_drive_from_type\n",
    "\n",
    "df_clean, summary = impute_drive_from_type(df_clean)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally drop type nulls \n",
    "from data_type import drop_na_type\n",
    "\n",
    "df_clean, summary =drop_na_type(df_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('clean_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>region</th>\n",
       "      <th>region_url</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>fuel</th>\n",
       "      <th>...</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>description</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>cylinders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>7316814884</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>33590</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>gmc</td>\n",
       "      <td>Sierra</td>\n",
       "      <td>gas</td>\n",
       "      <td>...</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>white</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.5900</td>\n",
       "      <td>-85.480000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>7316814758</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>22590</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>silverado</td>\n",
       "      <td>gas</td>\n",
       "      <td>...</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>blue</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.5900</td>\n",
       "      <td>-85.480000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>7316814989</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>39590</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>silverado</td>\n",
       "      <td>gas</td>\n",
       "      <td>...</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>red</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.5900</td>\n",
       "      <td>-85.480000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>7316743432</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>30990</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>toyota</td>\n",
       "      <td>Tundra</td>\n",
       "      <td>gas</td>\n",
       "      <td>...</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>red</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.5900</td>\n",
       "      <td>-85.480000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>7316356412</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>15000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>F-150</td>\n",
       "      <td>gas</td>\n",
       "      <td>...</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rwd</td>\n",
       "      <td>truck</td>\n",
       "      <td>black</td>\n",
       "      <td>2013 F-150 XLT V6 4 Door. Good condition. Leve...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.5920</td>\n",
       "      <td>-85.518900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>7316343444</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>27990</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>gmc</td>\n",
       "      <td>Sierra</td>\n",
       "      <td>gas</td>\n",
       "      <td>...</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>black</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.5900</td>\n",
       "      <td>-85.480000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>7316304717</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>34590</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>silverado</td>\n",
       "      <td>gas</td>\n",
       "      <td>...</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>silver</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.5900</td>\n",
       "      <td>-85.480000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>7316285779</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>35000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>toyota</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>gas</td>\n",
       "      <td>...</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>truck</td>\n",
       "      <td>grey</td>\n",
       "      <td>Selling my 2019 Toyota Tacoma TRD Off Road Dou...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.6013</td>\n",
       "      <td>-85.443974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>7316257769</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>29990</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>colorado</td>\n",
       "      <td>gas</td>\n",
       "      <td>...</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>red</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.5900</td>\n",
       "      <td>-85.480000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>7316133914</td>\n",
       "      <td>auburn</td>\n",
       "      <td>https://auburn.craigslist.org</td>\n",
       "      <td>38590</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>corvette</td>\n",
       "      <td>gas</td>\n",
       "      <td>...</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>rwd</td>\n",
       "      <td>other</td>\n",
       "      <td>red</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>al</td>\n",
       "      <td>32.5900</td>\n",
       "      <td>-85.480000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0          id  region  \\\n",
       "0             0          27  7316814884  auburn   \n",
       "1             1          28  7316814758  auburn   \n",
       "2             2          29  7316814989  auburn   \n",
       "3             3          30  7316743432  auburn   \n",
       "4             4          31  7316356412  auburn   \n",
       "5             5          32  7316343444  auburn   \n",
       "6             6          33  7316304717  auburn   \n",
       "7             7          34  7316285779  auburn   \n",
       "8             8          35  7316257769  auburn   \n",
       "9             9          36  7316133914  auburn   \n",
       "\n",
       "                      region_url  price    year manufacturer      model fuel  \\\n",
       "0  https://auburn.craigslist.org  33590  2014.0          gmc     Sierra  gas   \n",
       "1  https://auburn.craigslist.org  22590  2010.0    chevrolet  silverado  gas   \n",
       "2  https://auburn.craigslist.org  39590  2020.0    chevrolet  silverado  gas   \n",
       "3  https://auburn.craigslist.org  30990  2017.0       toyota     Tundra  gas   \n",
       "4  https://auburn.craigslist.org  15000  2013.0         ford      F-150  gas   \n",
       "5  https://auburn.craigslist.org  27990  2012.0          gmc     Sierra  gas   \n",
       "6  https://auburn.craigslist.org  34590  2016.0    chevrolet  silverado  gas   \n",
       "7  https://auburn.craigslist.org  35000  2019.0       toyota     tacoma  gas   \n",
       "8  https://auburn.craigslist.org  29990  2016.0    chevrolet   colorado  gas   \n",
       "9  https://auburn.craigslist.org  38590  2011.0    chevrolet   corvette  gas   \n",
       "\n",
       "   ...  title_status transmission drive    type paint_color  \\\n",
       "0  ...         clean        other   4wd  pickup       white   \n",
       "1  ...         clean        other   4wd  pickup        blue   \n",
       "2  ...         clean        other   4wd  pickup         red   \n",
       "3  ...         clean        other   4wd  pickup         red   \n",
       "4  ...         clean    automatic   rwd   truck       black   \n",
       "5  ...         clean        other   4wd  pickup       black   \n",
       "6  ...         clean        other   4wd  pickup      silver   \n",
       "7  ...         clean    automatic   4wd   truck        grey   \n",
       "8  ...         clean        other   4wd  pickup         red   \n",
       "9  ...         clean        other   rwd   other         red   \n",
       "\n",
       "                                         description state      lat  \\\n",
       "0  Carvana is the safer way to buy a car During t...    al  32.5900   \n",
       "1  Carvana is the safer way to buy a car During t...    al  32.5900   \n",
       "2  Carvana is the safer way to buy a car During t...    al  32.5900   \n",
       "3  Carvana is the safer way to buy a car During t...    al  32.5900   \n",
       "4  2013 F-150 XLT V6 4 Door. Good condition. Leve...    al  32.5920   \n",
       "5  Carvana is the safer way to buy a car During t...    al  32.5900   \n",
       "6  Carvana is the safer way to buy a car During t...    al  32.5900   \n",
       "7  Selling my 2019 Toyota Tacoma TRD Off Road Dou...    al  32.6013   \n",
       "8  Carvana is the safer way to buy a car During t...    al  32.5900   \n",
       "9  Carvana is the safer way to buy a car During t...    al  32.5900   \n",
       "\n",
       "        long  cylinders  \n",
       "0 -85.480000        NaN  \n",
       "1 -85.480000        NaN  \n",
       "2 -85.480000        NaN  \n",
       "3 -85.480000        NaN  \n",
       "4 -85.518900        NaN  \n",
       "5 -85.480000        NaN  \n",
       "6 -85.480000        NaN  \n",
       "7 -85.443974        NaN  \n",
       "8 -85.480000        NaN  \n",
       "9 -85.480000        NaN  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df =pd.read_csv('clean_v2.csv') \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.drop(['Unnamed: 0.2','Unnamed: 0.1','Unnamed: 0'],axis=1)\n",
    "df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_cleaning import filter_by_value_counts\n",
    "\n",
    "df = filter_by_value_counts(df, 'model', min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets explore other columns \n",
    "\n",
    "df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(dict(df['manufacturer'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manufacturer'] = df['manufacturer'].replace({\n",
    "    'land rover': 'land-rover',\n",
    "    'rover': 'land-rover',\n",
    "    'land rover': 'land-rover'  # in case there are duplicates\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['manufacturer']== 'harley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_manufacturers(df, manufacturer_column='manufacturer'):\n",
    "    \"\"\"\n",
    "    Validate and filter DataFrame to keep only rows with approved manufacturers\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame\n",
    "    manufacturer_column (str): Name of the manufacturer column\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Filtered DataFrame with only valid manufacturers\n",
    "    dict: Summary of validation results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Valid manufacturers list\n",
    "    valid_manufacturers = [\n",
    "        'acura', 'alfa-romeo', 'am-general', 'amc', 'audi', 'bentley', 'bmw', \n",
    "        'buick', 'cadillac', 'chevrolet', 'chrysler', 'dodge', 'eagle', 'ferrari', \n",
    "        'fiat', 'ford', 'freightliner', 'geo', 'gmc', 'hino', 'honda', 'hyundai', \n",
    "        'infiniti', 'international', 'isuzu', 'jaguar', 'jeep', 'kaiser', 'kenworth', \n",
    "        'kia', 'lamborghini', 'land-rover', 'lexus', 'lincoln', 'lotus', 'maserati', \n",
    "        'mazda', 'mclaren', 'mercedes-benz', 'mercury', 'mg', 'mini', 'mitsubishi', \n",
    "        'nash', 'nissan', 'oldsmobile', 'packard', 'peterbilt', 'plymouth', 'polaris', \n",
    "        'pontiac', 'porsche', 'ram', 'rolls-royce', 'saab', 'saturn', 'smart', \n",
    "        'sterling', 'studebaker', 'subaru', 'suzuki', 'tesla', 'toyota', 'triumph', \n",
    "        'volkswagen', 'volvo', 'vpg', 'western-star', 'willys'\n",
    "    ]\n",
    "    \n",
    "    # Store original info\n",
    "    original_count = len(df)\n",
    "    original_manufacturers = df[manufacturer_column].value_counts()\n",
    "    \n",
    "    # Find invalid manufacturers\n",
    "    invalid_manufacturers = df[~df[manufacturer_column].isin(valid_manufacturers)][manufacturer_column].value_counts()\n",
    "    \n",
    "    # Filter DataFrame\n",
    "    filtered_df = df[df[manufacturer_column].isin(valid_manufacturers)].copy()\n",
    "    \n",
    "    # Create summary\n",
    "    validation_summary = {\n",
    "        'original_rows': original_count,\n",
    "        'filtered_rows': len(filtered_df),\n",
    "        'dropped_rows': original_count - len(filtered_df),\n",
    "        'drop_percentage': round((original_count - len(filtered_df)) / original_count * 100, 2),\n",
    "        'valid_manufacturers_count': len(valid_manufacturers),\n",
    "        'found_manufacturers_count': len(original_manufacturers),\n",
    "        'invalid_manufacturers': dict(invalid_manufacturers)\n",
    "    }\n",
    "    \n",
    "    return filtered_df, validation_summary\n",
    "\n",
    "# Usage\n",
    "filtered_df, summary = validate_manufacturers(df)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Original rows: {summary['original_rows']}\")\n",
    "print(f\"Filtered rows: {summary['filtered_rows']}\")\n",
    "print(f\"Dropped rows: {summary['dropped_rows']} ({summary['drop_percentage']}%)\")\n",
    "print(f\"\\nInvalid manufacturers found:\")\n",
    "for manufacturer, count in summary['invalid_manufacturers'].items():\n",
    "    print(f\"  - {manufacturer}: {count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['paint_color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_paint_color_nulls(df, paint_color_col='paint_color', manufacturer_col='manufacturer', state_col='state'):\n",
    "    \"\"\"\n",
    "    Fill null values in paint_color column based on most common color \n",
    "    for each manufacturer-state combination\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame\n",
    "    paint_color_col (str): Name of the paint color column\n",
    "    manufacturer_col (str): Name of the manufacturer column  \n",
    "    state_col (str): Name of the state column\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with filled paint_color values\n",
    "    dict: Summary of filling operation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    df_filled = df.copy()\n",
    "    \n",
    "    # Count nulls before filling\n",
    "    nulls_before = df_filled[paint_color_col].isnull().sum()\n",
    "    total_rows = len(df_filled)\n",
    "    \n",
    "    # Step 1: Fill based on manufacturer + state combination\n",
    "    manufacturer_state_mode = df_filled.groupby([manufacturer_col, state_col])[paint_color_col].agg(\n",
    "        lambda x: x.mode().iloc[0] if len(x.mode()) > 0 and not x.mode().empty else None\n",
    "    ).to_dict()\n",
    "    \n",
    "    # Create mask for nulls\n",
    "    null_mask = df_filled[paint_color_col].isnull()\n",
    "    \n",
    "    # Fill nulls with manufacturer-state mode\n",
    "    for idx in df_filled[null_mask].index:\n",
    "        manufacturer = df_filled.loc[idx, manufacturer_col]\n",
    "        state = df_filled.loc[idx, state_col]\n",
    "        \n",
    "        if (manufacturer, state) in manufacturer_state_mode:\n",
    "            mode_color = manufacturer_state_mode[(manufacturer, state)]\n",
    "            if pd.notna(mode_color):\n",
    "                df_filled.loc[idx, paint_color_col] = mode_color\n",
    "    \n",
    "    # Step 2: Fill remaining nulls with manufacturer-only mode\n",
    "    still_null_mask = df_filled[paint_color_col].isnull()\n",
    "    manufacturer_mode = df_filled.groupby(manufacturer_col)[paint_color_col].agg(\n",
    "        lambda x: x.mode().iloc[0] if len(x.mode()) > 0 and not x.mode().empty else None\n",
    "    ).to_dict()\n",
    "    \n",
    "    for idx in df_filled[still_null_mask].index:\n",
    "        manufacturer = df_filled.loc[idx, manufacturer_col]\n",
    "        \n",
    "        if manufacturer in manufacturer_mode:\n",
    "            mode_color = manufacturer_mode[manufacturer]\n",
    "            if pd.notna(mode_color):\n",
    "                df_filled.loc[idx, paint_color_col] = mode_color\n",
    "    \n",
    "    # Step 3: Fill any remaining nulls with overall most common color\n",
    "    remaining_null_mask = df_filled[paint_color_col].isnull()\n",
    "    if remaining_null_mask.sum() > 0:\n",
    "        overall_mode = df_filled[paint_color_col].mode()\n",
    "        if len(overall_mode) > 0:\n",
    "            df_filled.loc[remaining_null_mask, paint_color_col] = overall_mode.iloc[0]\n",
    "    \n",
    "    # Count nulls after filling\n",
    "    nulls_after = df_filled[paint_color_col].isnull().sum()\n",
    "    filled_count = nulls_before - nulls_after\n",
    "    \n",
    "    # Create summary\n",
    "    filling_summary = {\n",
    "        'total_rows': total_rows,\n",
    "        'nulls_before': nulls_before,\n",
    "        'nulls_after': nulls_after,\n",
    "        'filled_count': filled_count,\n",
    "        'fill_percentage': round((filled_count / nulls_before * 100), 2) if nulls_before > 0 else 0,\n",
    "        'manufacturer_state_combinations': len(manufacturer_state_mode),\n",
    "        'successful_combinations': sum(1 for v in manufacturer_state_mode.values() if pd.notna(v))\n",
    "    }\n",
    "    \n",
    "    return df_filled, filling_summary\n",
    "\n",
    "# Usage\n",
    "df, summary = fill_paint_color_nulls(df)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total rows: {summary['total_rows']}\")\n",
    "print(f\"Nulls before: {summary['nulls_before']}\")\n",
    "print(f\"Nulls after: {summary['nulls_after']}\")\n",
    "print(f\"Filled: {summary['filled_count']} ({summary['fill_percentage']}%)\")\n",
    "print(f\"Manufacturer-State combinations: {summary['manufacturer_state_combinations']}\")\n",
    "print(f\"Successful combinations: {summary['successful_combinations']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['region'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new region column ( replacing older one) to trim down to 9 regions according to the u.s censue data \n",
    "df['state'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_census_divisions_abbrev(df, state_col='state', new_col='census_region'):\n",
    "    \"\"\"\n",
    "    Add U.S. Census Bureau Regional Divisions based on state abbreviations\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame\n",
    "    state_col (str): Name of the state column (with abbreviations)\n",
    "    new_col (str): Name of the new census division column\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with new census division column\n",
    "    \"\"\"\n",
    "    \n",
    "    # U.S. Census Bureau Regional Divisions mapping (state abbreviations)\n",
    "    census_divisions = {\n",
    "        # New England\n",
    "        'ct': 'New England',  # Connecticut\n",
    "        'me': 'New England',  # Maine\n",
    "        'ma': 'New England',  # Massachusetts\n",
    "        'nh': 'New England',  # New Hampshire\n",
    "        'ri': 'New England',  # Rhode Island\n",
    "        'vt': 'New England',  # Vermont\n",
    "        \n",
    "        # Middle Atlantic\n",
    "        'nj': 'Middle Atlantic',  # New Jersey\n",
    "        'ny': 'Middle Atlantic',  # New York\n",
    "        'pa': 'Middle Atlantic',  # Pennsylvania\n",
    "        \n",
    "        # East North Central\n",
    "        'il': 'East North Central',  # Illinois\n",
    "        'in': 'East North Central',  # Indiana\n",
    "        'mi': 'East North Central',  # Michigan\n",
    "        'oh': 'East North Central',  # Ohio\n",
    "        'wi': 'East North Central',  # Wisconsin\n",
    "        \n",
    "        # West North Central\n",
    "        'ia': 'West North Central',  # Iowa\n",
    "        'ks': 'West North Central',  # Kansas\n",
    "        'mn': 'West North Central',  # Minnesota\n",
    "        'mo': 'West North Central',  # Missouri\n",
    "        'ne': 'West North Central',  # Nebraska\n",
    "        'nd': 'West North Central',  # North Dakota\n",
    "        'sd': 'West North Central',  # South Dakota\n",
    "        \n",
    "        # South Atlantic\n",
    "        'de': 'South Atlantic',  # Delaware\n",
    "        'fl': 'South Atlantic',  # Florida\n",
    "        'ga': 'South Atlantic',  # Georgia\n",
    "        'md': 'South Atlantic',  # Maryland\n",
    "        'nc': 'South Atlantic',  # North Carolina\n",
    "        'sc': 'South Atlantic',  # South Carolina\n",
    "        'va': 'South Atlantic',  # Virginia\n",
    "        'wv': 'South Atlantic',  # West Virginia\n",
    "        'dc': 'South Atlantic',  # Washington DC\n",
    "        \n",
    "        # East South Central\n",
    "        'al': 'East South Central',  # Alabama\n",
    "        'ky': 'East South Central',  # Kentucky\n",
    "        'ms': 'East South Central',  # Mississippi\n",
    "        'tn': 'East South Central',  # Tennessee\n",
    "        \n",
    "        # West South Central\n",
    "        'ar': 'West South Central',  # Arkansas\n",
    "        'la': 'West South Central',  # Louisiana\n",
    "        'ok': 'West South Central',  # Oklahoma\n",
    "        'tx': 'West South Central',  # Texas\n",
    "        \n",
    "        # Mountain\n",
    "        'az': 'Mountain',  # Arizona\n",
    "        'co': 'Mountain',  # Colorado\n",
    "        'id': 'Mountain',  # Idaho\n",
    "        'mt': 'Mountain',  # Montana\n",
    "        'nv': 'Mountain',  # Nevada\n",
    "        'nm': 'Mountain',  # New Mexico\n",
    "        'ut': 'Mountain',  # Utah\n",
    "        'wy': 'Mountain',  # Wyoming\n",
    "        \n",
    "        # Pacific\n",
    "        'ak': 'Pacific',  # Alaska\n",
    "        'ca': 'Pacific',  # California\n",
    "        'hi': 'Pacific',  # Hawaii\n",
    "        'or': 'Pacific',  # Oregon\n",
    "        'wa': 'Pacific'   # Washington\n",
    "    }\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df_with_divisions = df.copy()\n",
    "    \n",
    "    # Map state abbreviations to census divisions\n",
    "    df_with_divisions[new_col] = df_with_divisions[state_col].map(census_divisions)\n",
    "    \n",
    "    # Check for unmapped states\n",
    "    unmapped_states = df_with_divisions[df_with_divisions[new_col].isnull()][state_col].unique()\n",
    "    \n",
    "    # Summary\n",
    "    mapping_summary = {\n",
    "        'total_rows': len(df_with_divisions),\n",
    "        'mapped_rows': df_with_divisions[new_col].notna().sum(),\n",
    "        'unmapped_rows': df_with_divisions[new_col].isna().sum(),\n",
    "        'unmapped_states': list(unmapped_states),\n",
    "        'divisions_found': df_with_divisions[new_col].nunique()\n",
    "    }\n",
    "    \n",
    "    return df_with_divisions, mapping_summary\n",
    "\n",
    "# Usage\n",
    "df, summary = add_census_divisions_abbrev(df)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total rows: {summary['total_rows']}\")\n",
    "print(f\"Mapped rows: {summary['mapped_rows']}\")\n",
    "print(f\"Unmapped rows: {summary['unmapped_rows']}\")\n",
    "print(f\"Census divisions found: {summary['divisions_found']}\")\n",
    "\n",
    "if summary['unmapped_states']:\n",
    "    print(f\"Unmapped states: {summary['unmapped_states']}\")\n",
    "\n",
    "# View the distribution\n",
    "print(\"\\nCensus Division Distribution:\")\n",
    "print(df['census_region'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['year'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Car Years')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_years(df, year_column='year', min_year=1990):\n",
    "    \"\"\"\n",
    "    Validate and filter DataFrame to keep only rows with years >= min_year\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame\n",
    "    year_column (str): Name of the year column\n",
    "    min_year (int): Minimum year to keep (default: 1990)\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Filtered DataFrame with only valid years\n",
    "    dict: Summary of validation results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Store original info\n",
    "    original_count = len(df)\n",
    "    original_year_range = (df[year_column].min(), df[year_column].max())\n",
    "    \n",
    "    # Find invalid years (older than min_year)\n",
    "    invalid_years_mask = df[year_column] < min_year\n",
    "    invalid_years = df[invalid_years_mask][year_column].value_counts().sort_index()\n",
    "    \n",
    "    # Also check for null values\n",
    "    null_years = df[year_column].isnull().sum()\n",
    "    \n",
    "    # Filter DataFrame to keep only valid years\n",
    "    filtered_df = df[df[year_column] >= min_year].copy()\n",
    "    \n",
    "    # Remove null values as well\n",
    "    filtered_df = filtered_df[filtered_df[year_column].notna()].copy()\n",
    "    \n",
    "    # Calculate new year range\n",
    "    if len(filtered_df) > 0:\n",
    "        new_year_range = (filtered_df[year_column].min(), filtered_df[year_column].max())\n",
    "    else:\n",
    "        new_year_range = (None, None)\n",
    "    \n",
    "    # Create summary\n",
    "    validation_summary = {\n",
    "        'original_rows': original_count,\n",
    "        'filtered_rows': len(filtered_df),\n",
    "        'dropped_rows': original_count - len(filtered_df),\n",
    "        'drop_percentage': round((original_count - len(filtered_df)) / original_count * 100, 2),\n",
    "        'min_year_threshold': min_year,\n",
    "        'original_year_range': original_year_range,\n",
    "        'new_year_range': new_year_range,\n",
    "        'null_years': null_years,\n",
    "        'invalid_years_count': len(invalid_years),\n",
    "        'invalid_years_breakdown': dict(invalid_years)\n",
    "    }\n",
    "    \n",
    "    return filtered_df, validation_summary\n",
    "\n",
    "# Usage\n",
    "df, summary = validate_years(df, year_column='year', min_year=1990)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Original rows: {summary['original_rows']}\")\n",
    "print(f\"Filtered rows: {summary['filtered_rows']}\")\n",
    "print(f\"Dropped rows: {summary['dropped_rows']} ({summary['drop_percentage']}%)\")\n",
    "print(f\"Original year range: {summary['original_year_range'][0]} - {summary['original_year_range'][1]}\")\n",
    "print(f\"New year range: {summary['new_year_range'][0]} - {summary['new_year_range'][1]}\")\n",
    "print(f\"Null years: {summary['null_years']}\")\n",
    "\n",
    "if summary['invalid_years_breakdown']:\n",
    "    print(f\"\\nInvalid years found (< {summary['min_year_threshold']}):\")\n",
    "    for year, count in summary['invalid_years_breakdown'].items():\n",
    "        print(f\"  - {year}: {count} cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['year'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check price statistics\n",
    "print(df['price'].describe())\n",
    "print(f\"Price range: ${df['price'].min():,.0f} - ${df['price'].max():,.0f}\")\n",
    "\n",
    "# Check for extreme outliers\n",
    "print(f\"99th percentile: ${df['price'].quantile(0.99):,.0f}\")\n",
    "print(f\"95th percentile: ${df['price'].quantile(0.95):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price_data(df, price_col='price'):\n",
    "    \"\"\"Clean price data by removing invalid and extreme outliers\"\"\"\n",
    "    \n",
    "    original_count = len(df)\n",
    "    \n",
    "    # Remove invalid prices\n",
    "    df_clean = df[df[price_col] > 0].copy()  # Remove $0 prices\n",
    "    \n",
    "    # Set reasonable price limits for used cars\n",
    "    min_price = 500      # Minimum reasonable car price\n",
    "    max_price = 100000   # Maximum reasonable used car price\n",
    "    \n",
    "    df_clean = df_clean[(df_clean[price_col] >= min_price) & \n",
    "                        (df_clean[price_col] <= max_price)]\n",
    "    \n",
    "    # Or use percentile-based filtering (more conservative)\n",
    "    # q99 = df_clean[price_col].quantile(0.99)\n",
    "    # df_clean = df_clean[df_clean[price_col] <= q99]\n",
    "    \n",
    "    dropped_count = original_count - len(df_clean)\n",
    "    \n",
    "    print(f\"Original rows: {original_count:,}\")\n",
    "    print(f\"Cleaned rows: {len(df_clean):,}\")\n",
    "    print(f\"Dropped rows: {dropped_count:,} ({dropped_count/original_count*100:.1f}%)\")\n",
    "    \n",
    "    # New statistics\n",
    "    print(f\"\\nCleaned price range: ${df_clean[price_col].min():,.0f} - ${df_clean[price_col].max():,.0f}\")\n",
    "    print(f\"New mean: ${df_clean[price_col].mean():,.0f}\")\n",
    "    print(f\"New std: ${df_clean[price_col].std():,.0f}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean your data\n",
    "df = clean_price_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['price'], bins=30000, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Car Price')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(df['price'], vert=False)\n",
    "plt.xlabel('Price ($)')\n",
    "plt.title('Price Distribution - Box Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transmission'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[df['fuel']=='other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transmission column \n",
    "\n",
    "from data_transmission import convert_transmission_to_automatic , validate_transmission_values \n",
    "\n",
    "df, summary = convert_transmission_to_automatic(df)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total rows: {summary['total_rows']}\")\n",
    "print(f\"Original unique values: {summary['original_unique_values']}\")\n",
    "print(f\"New unique values: {summary['new_unique_values']}\")\n",
    "print(f\"Converted to automatic: {summary['converted_to_automatic']}\")\n",
    "\n",
    "print(\"\\nOriginal value counts:\")\n",
    "for value, count in summary['original_value_counts'].items():\n",
    "    print(f\"  - {value}: {count}\")\n",
    "\n",
    "print(\"\\nNew value counts:\")\n",
    "for value, count in summary['new_value_counts'].items():\n",
    "    print(f\"  - {value}: {count}\") \n",
    "\n",
    "\n",
    "# Usage\n",
    "df, validation_summary = validate_transmission_values(df)\n",
    "\n",
    "# Print validation results\n",
    "print(f\"Validation Results:\")\n",
    "print(f\"Total rows: {validation_summary['total_rows']}\")\n",
    "print(f\"Valid rows: {validation_summary['valid_rows']}\")\n",
    "print(f\"Dropped rows: {validation_summary['dropped_rows']} ({validation_summary['drop_percentage']}%)\")\n",
    "print(f\"Validation passed: {validation_summary['validation_passed']}\")\n",
    "\n",
    "if validation_summary['invalid_values']:\n",
    "    print(f\"\\nInvalid values found:\")\n",
    "    for value, count in validation_summary['invalid_values'].items():\n",
    "        print(f\"  - '{value}': {count} rows\")\n",
    "\n",
    "if validation_summary['null_values'] > 0:\n",
    "    print(f\"\\nNull values: {validation_summary['null_values']}\")\n",
    "\n",
    "print(f\"\\nFinal value counts:\")\n",
    "for value, count in df['transmission'].value_counts().items():\n",
    "    print(f\"  - {value}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_fuel import validate_fuel_values, convert_fuel_to_gas\n",
    "\n",
    "# Usage\n",
    "df, summary = convert_transmission_to_automatic(df)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total rows: {summary['total_rows']}\")\n",
    "print(f\"Original unique values: {summary['original_unique_values']}\")\n",
    "print(f\"New unique values: {summary['new_unique_values']}\")\n",
    "print(f\"Converted to automatic: {summary['converted_to_automatic']}\")\n",
    "\n",
    "print(\"\\nOriginal value counts:\")\n",
    "for value, count in summary['original_value_counts'].items():\n",
    "    print(f\"  - {value}: {count}\")\n",
    "\n",
    "print(\"\\nNew value counts:\")\n",
    "for value, count in summary['new_value_counts'].items():\n",
    "    print(f\"  - {value}: {count}\")\n",
    "\n",
    "# Usage\n",
    "df, validation_summary = validate_transmission_values(df)\n",
    "\n",
    "# Print validation results\n",
    "print(f\"Validation Results:\")\n",
    "print(f\"Total rows: {validation_summary['total_rows']}\")\n",
    "print(f\"Valid rows: {validation_summary['valid_rows']}\")\n",
    "print(f\"Dropped rows: {validation_summary['dropped_rows']} ({validation_summary['drop_percentage']}%)\")\n",
    "print(f\"Validation passed: {validation_summary['validation_passed']}\")\n",
    "\n",
    "if validation_summary['invalid_values']:\n",
    "    print(f\"\\nInvalid values found:\")\n",
    "    for value, count in validation_summary['invalid_values'].items():\n",
    "        print(f\"  - '{value}': {count} rows\")\n",
    "\n",
    "if validation_summary['null_values'] > 0:\n",
    "    print(f\"\\nNull values: {validation_summary['null_values']}\")\n",
    "\n",
    "print(f\"\\nFinal value counts:\")\n",
    "for value, count in df['transmission'].value_counts().items():\n",
    "    print(f\"  - {value}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.hist(df['odometer'],bins=1000)\n",
    "plt.xlabel('odometer')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of odometer')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions\n",
    "from data_odometer import process_odometer_column, preview_odometer_cleaning\n",
    "\n",
    "# Preview what will be cleaned\n",
    "preview_odometer_cleaning(df, 'odometer')\n",
    "\n",
    "# Clean the data (recommended approach)\n",
    "df, summary = process_odometer_column(df, 'odometer')\n",
    "\n",
    "# Check results\n",
    "print(f\"Removed {summary['total_removed']} rows ({summary['total_removal_percentage']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.hist(df['odometer'],bins=1000)\n",
    "plt.xlabel('odometer')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of odometer')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('clean_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_title_status import validate_title_status_values \n",
    "\n",
    "df, validation_summary = validate_title_status_values(df)\n",
    "\n",
    "print(\"Title Status Validation Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total rows: {validation_summary['total_rows']:,}\")\n",
    "print(f\"Valid rows: {validation_summary['valid_rows']:,}\")\n",
    "print(f\"Dropped rows: {validation_summary['dropped_rows']:,}\")\n",
    "print(f\"Drop percentage: {validation_summary['drop_percentage']}%\")\n",
    "print(f\"Validation passed: {'âœ… Yes' if validation_summary['validation_passed'] else 'âŒ No'}\")\n",
    "    \n",
    "print(f\"\\nValid values: {validation_summary['valid_values']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_type import validate_type_values\n",
    "df, summary = validate_type_values(df, standardize_case=True)\n",
    "\n",
    "\n",
    "print(f\"\\n\")\n",
    "\n",
    "print(f\"\\nCleaned DataFrame (with standardized case):\")\n",
    "print(df)\n",
    "print(f\"\\nCleaned value counts:\")\n",
    "print(df['type'].value_counts())\n",
    "    \n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"Example WITHOUT case standardization:\")\n",
    "cleaned_df_no_std, summary_no_std = validate_type_values(df, standardize_case=True)\n",
    "print(f\"Rows kept with case standardization: {len(df)}\")\n",
    "print(f\"Rows kept without case standardization: {len(cleaned_df_no_std)}\")\n",
    "print(f\"Difference: {len(df) - len(cleaned_df_no_std)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deal_Predection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
