{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "from utility.print_summary import print_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                                url  \\\n",
      "0  7222695916  https://prescott.craigslist.org/cto/d/prescott...   \n",
      "1  7218891961  https://fayar.craigslist.org/ctd/d/bentonville...   \n",
      "2  7221797935  https://keys.craigslist.org/cto/d/summerland-k...   \n",
      "3  7222270760  https://worcester.craigslist.org/cto/d/west-br...   \n",
      "4  7210384030  https://greensboro.craigslist.org/cto/d/trinit...   \n",
      "\n",
      "                   region                         region_url  price  year  \\\n",
      "0                prescott    https://prescott.craigslist.org   6000   NaN   \n",
      "1            fayetteville       https://fayar.craigslist.org  11900   NaN   \n",
      "2            florida keys        https://keys.craigslist.org  21000   NaN   \n",
      "3  worcester / central MA   https://worcester.craigslist.org   1500   NaN   \n",
      "4              greensboro  https://greensboro.craigslist.org   4900   NaN   \n",
      "\n",
      "  manufacturer model condition cylinders  ... size  type paint_color  \\\n",
      "0          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n",
      "1          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n",
      "2          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n",
      "3          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n",
      "4          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n",
      "\n",
      "  image_url description county state lat long posting_date  \n",
      "0       NaN         NaN    NaN    az NaN  NaN          NaN  \n",
      "1       NaN         NaN    NaN    ar NaN  NaN          NaN  \n",
      "2       NaN         NaN    NaN    fl NaN  NaN          NaN  \n",
      "3       NaN         NaN    NaN    ma NaN  NaN          NaN  \n",
      "4       NaN         NaN    NaN    nc NaN  NaN          NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/dhruvpatel/Desktop/projects/DealPredection/data/vehicles.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# standardizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data extraction and cleaning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruvpatel/miniconda3/envs/Deal_Predection/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction and cleaning completed!\n"
     ]
    }
   ],
   "source": [
    "#  standardization  and extracting info from model and description.\n",
    "from DataCleaning.data_model import process_car_dataset\n",
    "\n",
    "featured_eng=process_car_dataset(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Columns: 26\n",
      "Final Columns: 16\n",
      "Dropped Columns: ['url', 'image_url', 'county', 'VIN', 'size', 'condition', 'posting_date', 'cylinders', 'region', 'region_url']\n",
      "Missing Columns: []\n",
      "Columns Dropped Count: 10\n",
      "Columns Remaining: ['id', 'price', 'year', 'manufacturer', 'model', 'fuel', 'odometer', 'title_status', 'transmission', 'drive', 'type', 'paint_color', 'description', 'state', 'lat', 'long']\n"
     ]
    }
   ],
   "source": [
    "# dropping  unnecessory columns\n",
    "from DataCleaning.data_cleaning import drop_unnecessary_columns , drop_rows_with_few_missing_values\n",
    "\n",
    "df, summary = drop_unnecessary_columns(df) \n",
    "print_summary(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 426,880\n",
      "Final Rows: 390,217\n",
      "Dropped Rows: 36,663\n",
      "Drop Percentage: 8.59\n",
      "Columns With Few Missing: ['year', 'description', 'fuel', 'odometer', 'lat', 'long', 'transmission', 'model', 'manufacturer']\n",
      "Missing Columns: []\n",
      "Missing Counts Before: {'year': np.int64(1205), 'description': np.int64(70), 'fuel': np.int64(3013), 'odometer': np.int64(4400), 'lat': np.int64(6549), 'long': np.int64(6549), 'transmission': np.int64(2556), 'model': np.int64(5277), 'manufacturer': np.int64(17646)}\n",
      "Total Missing Values: 47265\n"
     ]
    }
   ],
   "source": [
    "# dropping rows due to high NAs \n",
    "\n",
    "df, summary = df_cleaned, summary = drop_rows_with_few_missing_values(df) \n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Column Name: title_status\n",
      "Fill Value: missing\n",
      "Missing Before: 6730\n",
      "Missing After: 0\n",
      "Values Filled: 6730\n",
      "Total Rows: 390,217\n"
     ]
    }
   ],
   "source": [
    "# filling missing values in title status with 'missing' \n",
    "from DataCleaning.data_title_status import fill_missing_values \n",
    "\n",
    "df,summary = fill_missing_values(df) \n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Column Name: transmission\n",
      "Fill Value: automatic\n",
      "Missing Before: 0\n",
      "Missing After: 0\n",
      "Values Filled: 0\n",
      "Total Rows: 390,217\n",
      "Summary\n",
      "=======\n",
      "Column Name: transmission\n",
      "Fill Value: automatic\n",
      "Missing Before: 0\n",
      "Missing After: 0\n",
      "Values Filled: 0\n",
      "Total Rows: 390,217\n"
     ]
    }
   ],
   "source": [
    "from DataCleaning.data_transmission import fill_missing_values_transmission, convert_transmission_to_automatic \n",
    "\n",
    "\n",
    "df,summary = fill_missing_values_transmission(df) \n",
    "print_summary(summary)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 390,217\n",
      "Original Unique Values: 3\n",
      "New Unique Values: 2\n",
      "Original Value Counts: {'automatic': 309758, 'other': 59435, 'manual': 21024}\n",
      "New Value Counts: {'automatic': 369193, 'manual': 21024}\n",
      "Converted To Automatic: 369,193\n"
     ]
    }
   ],
   "source": [
    "df, summary = convert_transmission_to_automatic(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drive column cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardasition \n",
    "from DataCleaning.data_drive import clean_drive_column\n",
    "df,summary=clean_drive_column(df, 'drive')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 390,217\n",
      "Missing Before: 117577\n",
      "Missing After: 100574\n",
      "Values Filled: 17,003\n",
      "Models Not Found: 100,574\n",
      "Mappings Loaded: 83\n"
     ]
    }
   ],
   "source": [
    "# filling null values from research : (na values)\n",
    "from DataCleaning.data_drive import fill_missing_drive_from_reference\n",
    "\n",
    "\n",
    "df,summary = fill_missing_drive_from_reference(df,\n",
    "                                       reference_file='/Users/dhruvpatel/Desktop/projects/DealPredection/data/models_with_drive.csv'\n",
    "                                                 )\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "\n",
    "Clean in stages:\n",
    "* Stage 1: Remove obvious junk (numbers, too short, too long)\n",
    "* Stage 2: Extract core model from complex strings\n",
    "* Stage 3: Standardize spelling and format\n",
    "* Stage 4: Apply manufacturer-specific rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: DataFrame shape after cleaning: (377123, 16)\n",
      "Step: remove_numerical_models\n",
      "Rows removed due to numerical only: 11499\n",
      "Rows removed due to length > 40: 1595\n",
      "Total rows removed: 13094\n",
      "Summary\n",
      "=======\n",
      "Total Rows Before: 390,217\n",
      "Total Rows After: 377,123\n",
      "Rows Removed: 13,094\n",
      "Numerical Removed: 11499\n",
      "Length Removed: 1595\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 : Remove obvious junk (only numbers, too short, too long)\n",
    "\n",
    "from DataCleaning.data_model import remove_numerical_models\n",
    "\n",
    "df,summary =remove_numerical_models(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27              gmc\n",
       "28        chevrolet\n",
       "29        chevrolet\n",
       "30           toyota\n",
       "31             ford\n",
       "            ...    \n",
       "426875       nissan\n",
       "426876        volvo\n",
       "426877     cadillac\n",
       "426878        lexus\n",
       "426879          bmw\n",
       "Name: manufacturer, Length: 377123, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['manufacturer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimized model cleaning...\n",
      "Creating optimized lookup tables...\n",
      "Processing unique model values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing unique models: 100%|██████████| 22159/22159 [04:34<00:00, 80.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying results to DataFrame...\n",
      "Found 358210 models to update.\n",
      "Step: clean_models_with_list_optimized\n",
      "Total rows modified: 263172\n",
      "\n",
      "Sample transformations:\n",
      "  'sierra 1500 crew cab slt' (gmc) -> 'Sierra' (gmc)\n",
      "  'silverado 1500' (chevrolet) -> 'silverado' (chevrolet)\n",
      "  'silverado 1500 crew' (chevrolet) -> 'silverado' (chevrolet)\n",
      "  'tundra double cab sr' (toyota) -> 'Tundra' (toyota)\n",
      "  'f-150 xlt' (ford) -> 'F-150' (ford)\n",
      "  'sierra 2500 hd extended cab' (gmc) -> 'Sierra' (gmc)\n",
      "  'silverado 1500 double' (chevrolet) -> 'silverado' (chevrolet)\n",
      "  'colorado extended cab' (chevrolet) -> 'colorado' (chevrolet)\n",
      "  'corvette grand sport' (chevrolet) -> 'corvette' (chevrolet)\n",
      "  'cherokee' (jeep) -> 'Cherokee' (jeep)\n",
      "Summary\n",
      "=======\n",
      "Total Rows: 377,123\n",
      "Rows Modified: 263172\n",
      "Models Updated: 278506\n",
      "Manufacturers Updated: 65490\n",
      "Unique Models Processed: 22,159\n",
      "Lookup Tables Created: 1,923\n"
     ]
    }
   ],
   "source": [
    "from DataCleaning.data_model import clean_models_with_list_optimized\n",
    " \n",
    "df,summary = clean_models_with_list_optimized(df)  \n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "price                0\n",
       "year                 0\n",
       "manufacturer         0\n",
       "model                0\n",
       "fuel                 0\n",
       "odometer             0\n",
       "title_status         0\n",
       "transmission         0\n",
       "drive            97898\n",
       "type             79372\n",
       "paint_color     113544\n",
       "description          0\n",
       "state                0\n",
       "lat                  0\n",
       "long                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean model \n",
    "from DataCleaning.data_model import filter_by_value_counts\n",
    "\n",
    "df = filter_by_value_counts(df, 'model', min_count=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 370,883\n",
      "Final Rows: 331,111\n",
      "Rows Dropped: 39772\n",
      "Both Missing: 39772\n"
     ]
    }
   ],
   "source": [
    "from DataCleaning.data_type import drop_na_drive_type  \n",
    "\n",
    "df, summary = drop_na_drive_type(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 331,111\n",
      "Rows Changed: 4415\n",
      "Replacements: {'mini van': 'minivan', 'mini-van': 'minivan'}\n"
     ]
    }
   ],
   "source": [
    "# cleaning and standardasition  (type) \n",
    "from DataCleaning.data_type import replace_values \n",
    "df, summary =replace_values(df, 'type', {'mini van': 'minivan', 'mini-van': 'minivan'})\n",
    "print_summary(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 331,111\n",
      "Missing Before: 37782\n",
      "Missing After: 91\n",
      "Values Filled: 37691\n",
      "Mapping Created: 972\n"
     ]
    }
   ],
   "source": [
    "# filling null values based on data present. \n",
    "# First, let's see what we're working with\n",
    "\n",
    "from DataCleaning.data_type import fill_type_from_model\n",
    "\n",
    "df, summary = fill_type_from_model(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 331,111\n",
      "Final Rows: 331,020\n",
      "Rows Dropped: 91\n",
      "Missing Values: 91\n"
     ]
    }
   ],
   "source": [
    "# finally drop type nulls \n",
    "from DataCleaning.data_type import drop_na_type\n",
    "\n",
    "df_clean, summary =drop_na_type(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 331,111\n",
      "Missing Before: 56145\n",
      "Missing After: 0\n",
      "Values Imputed: 56145\n"
     ]
    }
   ],
   "source": [
    "# impute drive 1 ( based on cross tab type )\n",
    "\n",
    "from DataCleaning.data_drive import impute_drive_from_type\n",
    "\n",
    "df, summary = impute_drive_from_type(df)\n",
    "print_summary(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manufacturer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 331,111\n",
      "Rows Changed: 1094\n",
      "Replacements: {'land rover': 'land-rover', 'rover': 'land-rover'}\n"
     ]
    }
   ],
   "source": [
    "from DataCleaning.data_manufacturers import standardize_manufacturer \n",
    "\n",
    "df, summary =standardize_manufacturer(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paint Color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 331,111\n",
      "Nulls Before: 77782\n",
      "Nulls After: 0\n",
      "Filled Count: 77782\n",
      "Fill Percentage: 100.0\n",
      "Manufacturer State Combinations: 2,600\n",
      "Successful Combinations: 2,553\n"
     ]
    }
   ],
   "source": [
    "from DataCleaning.data_paint_color import fill_paint_color_nulls \n",
    "\n",
    "# Usage\n",
    "df, summary = fill_paint_color_nulls(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# census_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 331,111\n",
      "Mapped Rows: 331111\n",
      "Unmapped Rows: 0\n",
      "Unmapped States: []\n",
      "Divisions Found: 9\n"
     ]
    }
   ],
   "source": [
    "from  DataCleaning.data_census_region import add_census_divisions_abbrev , validate_regions\n",
    "\n",
    "# Usage\n",
    "df, summary = add_census_divisions_abbrev(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 331,111\n",
      "Rows After Cleaning: 301,980\n",
      "Total Rows Dropped: 29,131\n",
      "Zero Price Dropped: 22,277\n",
      "Out Of Range Dropped: 6,854\n",
      "Drop Rate Percent: 8.8\n",
      "Price Range Applied: $500 - $300,000\n",
      "Final Price Min: 500\n",
      "Final Price Max: 290000\n",
      "Final Price Mean: 19387.46\n",
      "Final Price Std: 14268.04\n"
     ]
    }
   ],
   "source": [
    "from DataCleaning.data_price import clean_price_data \n",
    "# Usage example:\n",
    "df, summary = clean_price_data(df, 'price')\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 301,980\n",
      "Original Unique Values: 5\n",
      "New Unique Values: 4\n",
      "Original Value Counts: {'gas': 257460, 'other': 24348, 'diesel': 14848, 'hybrid': 3974, 'electric': 1350}\n",
      "New Value Counts: {'gas': 281808, 'diesel': 14848, 'hybrid': 3974, 'electric': 1350}\n",
      "Converted To Gas: 24,348\n"
     ]
    }
   ],
   "source": [
    "from DataCleaning.data_fuel import  convert_fuel_to_gas\n",
    "\n",
    "\n",
    "df,summary = convert_fuel_to_gas(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# odometer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Removing extreme odometer values...\n",
      "\n",
      "Step 2: Validating odometer values...\n",
      "\n",
      "Final Results:\n",
      "Original rows: 301,980\n",
      "Final rows: 301,586\n",
      "Total removed: 394 (0.13%)\n",
      "Final odometer range: 0 - 500,000\n",
      "Final odometer mean: 89,618\n",
      "Summary\n",
      "=======\n",
      "Original Rows: 301,980\n",
      "Final Rows: 301,586\n",
      "Total Removed: 394\n",
      "Total Removal Percentage: 0.13\n",
      "Removal Summary: {'original_rows': 301980, 'cleaned_rows': 301586, 'removed_rows': 394, 'removal_percentage': 0.13, 'min_threshold': 0, 'max_threshold': 500000, 'extreme_low_count': 0, 'extreme_high_count': 394, 'null_count': np.int64(0), 'original_stats': {'count': 301980.0, 'mean': 92539.45117557455, 'std': 147118.78384392778, 'min': 0.0, '25%': 35326.0, '50%': 83301.0, '75%': 132000.0, 'max': 10000000.0}, 'cleaned_stats': {'count': 301586.0, 'mean': 89618.33646787317, 'std': 62483.48819244328, 'min': 0.0, '25%': 35290.0, '50%': 83141.5, '75%': 131904.0, 'max': 500000.0}}\n",
      "Validation Summary: {'total_rows': 301586, 'valid_rows': 301586, 'dropped_rows': 0, 'drop_percentage': 0.0, 'validation_range': (0, 500000), 'original_range': (np.float64(0.0), np.float64(500000.0)), 'new_range': (np.float64(0.0), np.float64(500000.0)), 'invalid_values': {'null_values': np.int64(0), 'below_minimum': np.int64(0), 'above_maximum': np.int64(0)}, 'validation_passed': np.True_}\n"
     ]
    }
   ],
   "source": [
    "# Import the functions\n",
    "from DataCleaning.data_odometer import process_odometer_column\n",
    "\n",
    "\n",
    "\n",
    "# Clean the data (recommended approach)\n",
    "df, summary = process_odometer_column(df, 'odometer')\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# validation columns \n",
    "\n",
    "1. census_region ✅ \n",
    "2. drive ✅\n",
    "3. fuel ✅\n",
    "4. lat  \n",
    "5. long\n",
    "6. manufacturer ✅ \n",
    "7. model ✅ \n",
    "8.  ✅\n",
    "9. paint_color ✅\n",
    "10. price ✅\n",
    "11. state ✅\n",
    "12. title_status ✅\n",
    "13. transmission ✅\n",
    "14. type ✅\n",
    "15. year ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 301,586\n",
      "Rows After Filtering: 301,586\n",
      "Rows Dropped: 0\n",
      "Invalid Regions Found: []\n",
      "Drop Rate Percent: 0.0\n",
      "Valid Regions: ['Mountain', 'West South Central', 'South Atlantic', 'West North Central', 'East North Central', 'Middle Atlantic', 'Pacific', 'East South Central', 'New England']\n"
     ]
    }
   ],
   "source": [
    "# 1 census_region \n",
    "df, summary = validate_regions(df) \n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 301,586\n",
      "Filtered Rows: 295,997\n",
      "Dropped Rows: 5,589\n",
      "Drop Percentage: 1.85\n",
      "Min Year Threshold: 1,990\n",
      "Original Year Range: 1900.0 - 2022.0\n",
      "New Year Range: 1990.0 - 2022.0\n",
      "Null Years: 0\n",
      "Invalid Years Count: 69\n",
      "Invalid Years Breakdown: {1900.0: np.int64(1), 1905.0: np.int64(1), 1915.0: np.int64(1), 1918.0: np.int64(1), 1922.0: np.int64(1), 1923.0: np.int64(20), 1924.0: np.int64(6), 1925.0: np.int64(4), 1926.0: np.int64(3), 1927.0: np.int64(14), 1928.0: np.int64(20), 1929.0: np.int64(25), 1930.0: np.int64(27), 1931.0: np.int64(15), 1932.0: np.int64(21), 1933.0: np.int64(7), 1934.0: np.int64(14), 1935.0: np.int64(8), 1936.0: np.int64(9), 1937.0: np.int64(12), 1938.0: np.int64(7), 1939.0: np.int64(11), 1940.0: np.int64(23), 1941.0: np.int64(17), 1942.0: np.int64(4), 1946.0: np.int64(21), 1947.0: np.int64(17), 1948.0: np.int64(14), 1949.0: np.int64(11), 1950.0: np.int64(20), 1951.0: np.int64(30), 1952.0: np.int64(27), 1953.0: np.int64(28), 1954.0: np.int64(16), 1955.0: np.int64(71), 1956.0: np.int64(51), 1957.0: np.int64(63), 1958.0: np.int64(13), 1959.0: np.int64(26), 1960.0: np.int64(56), 1961.0: np.int64(26), 1962.0: np.int64(66), 1963.0: np.int64(112), 1964.0: np.int64(136), 1965.0: np.int64(170), 1966.0: np.int64(229), 1967.0: np.int64(163), 1968.0: np.int64(220), 1969.0: np.int64(199), 1970.0: np.int64(147), 1971.0: np.int64(152), 1972.0: np.int64(185), 1973.0: np.int64(163), 1974.0: np.int64(120), 1975.0: np.int64(84), 1976.0: np.int64(98), 1977.0: np.int64(124), 1978.0: np.int64(175), 1979.0: np.int64(205), 1980.0: np.int64(139), 1981.0: np.int64(102), 1982.0: np.int64(110), 1983.0: np.int64(122), 1984.0: np.int64(192), 1985.0: np.int64(257), 1986.0: np.int64(279), 1987.0: np.int64(255), 1988.0: np.int64(277), 1989.0: np.int64(346)}\n"
     ]
    }
   ],
   "source": [
    "# 2 \n",
    "from DataCleaning.data_year import validate_years\n",
    "# Usage\n",
    "df, summary = validate_years(df, year_column='year', min_year=1990)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 301,586\n",
      "Filtered Rows: 295,997\n",
      "Dropped Rows: 5,589\n",
      "Drop Percentage: 1.85\n",
      "Min Year Threshold: 1,990\n",
      "Original Year Range: 1900.0 - 2022.0\n",
      "New Year Range: 1990.0 - 2022.0\n",
      "Null Years: 0\n",
      "Invalid Years Count: 69\n",
      "Invalid Years Breakdown: {1900.0: np.int64(1), 1905.0: np.int64(1), 1915.0: np.int64(1), 1918.0: np.int64(1), 1922.0: np.int64(1), 1923.0: np.int64(20), 1924.0: np.int64(6), 1925.0: np.int64(4), 1926.0: np.int64(3), 1927.0: np.int64(14), 1928.0: np.int64(20), 1929.0: np.int64(25), 1930.0: np.int64(27), 1931.0: np.int64(15), 1932.0: np.int64(21), 1933.0: np.int64(7), 1934.0: np.int64(14), 1935.0: np.int64(8), 1936.0: np.int64(9), 1937.0: np.int64(12), 1938.0: np.int64(7), 1939.0: np.int64(11), 1940.0: np.int64(23), 1941.0: np.int64(17), 1942.0: np.int64(4), 1946.0: np.int64(21), 1947.0: np.int64(17), 1948.0: np.int64(14), 1949.0: np.int64(11), 1950.0: np.int64(20), 1951.0: np.int64(30), 1952.0: np.int64(27), 1953.0: np.int64(28), 1954.0: np.int64(16), 1955.0: np.int64(71), 1956.0: np.int64(51), 1957.0: np.int64(63), 1958.0: np.int64(13), 1959.0: np.int64(26), 1960.0: np.int64(56), 1961.0: np.int64(26), 1962.0: np.int64(66), 1963.0: np.int64(112), 1964.0: np.int64(136), 1965.0: np.int64(170), 1966.0: np.int64(229), 1967.0: np.int64(163), 1968.0: np.int64(220), 1969.0: np.int64(199), 1970.0: np.int64(147), 1971.0: np.int64(152), 1972.0: np.int64(185), 1973.0: np.int64(163), 1974.0: np.int64(120), 1975.0: np.int64(84), 1976.0: np.int64(98), 1977.0: np.int64(124), 1978.0: np.int64(175), 1979.0: np.int64(205), 1980.0: np.int64(139), 1981.0: np.int64(102), 1982.0: np.int64(110), 1983.0: np.int64(122), 1984.0: np.int64(192), 1985.0: np.int64(257), 1986.0: np.int64(279), 1987.0: np.int64(255), 1988.0: np.int64(277), 1989.0: np.int64(346)}\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "# transmission column \n",
    "\n",
    "from DataCleaning.data_transmission import  validate_transmission_values \n",
    "\n",
    "df, validation_summary = validate_transmission_values(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 295,997\n",
      "Valid Rows: 295,997\n",
      "Dropped Rows: 0\n",
      "Drop Percentage: 0.0\n",
      "Valid Values: ['gas', 'diesel', 'hybrid', 'electric']\n",
      "Original Value Counts: {'gas': 275998, 'diesel': 14678, 'hybrid': 3972, 'electric': 1349}\n",
      "Invalid Values: {}\n",
      "Null Values: 0\n",
      "Validation Passed: True\n"
     ]
    }
   ],
   "source": [
    "# 4 \n",
    "from DataCleaning.data_fuel import validate_fuel_values\n",
    "df , summary = validate_fuel_values(df) \n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 295,997\n",
      "Valid Rows: 295,997\n",
      "Dropped Rows: 0\n",
      "Drop Percentage: 0.0\n",
      "Valid Values: ['clean', 'rebuilt', 'missing', 'salvage', 'lien', 'parts only']\n",
      "Original Value Counts: {'clean': 280797, 'missing': 5795, 'rebuilt': 5514, 'salvage': 2753, 'lien': 1076, 'parts only': 62}\n",
      "Invalid Values: {}\n",
      "Null Values: 0\n",
      "Validation Passed: True\n"
     ]
    }
   ],
   "source": [
    "# 5 \n",
    "from DataCleaning.data_title_status import validate_title_status_values \n",
    "\n",
    "df, summary = validate_title_status_values(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Total Rows: 295,997\n",
      "Valid Rows: 295,921\n",
      "Dropped Rows: 76\n",
      "Drop Percentage: 0.03\n",
      "Valid Values: ['sedan', 'suv', 'pickup', 'truck', 'other', 'coupe', 'hatchback', 'wagon', 'van', 'convertible', 'minivan', 'bus', 'offroad']\n",
      "Original Value Counts: {'sedan': 82353, 'SUV': 71130, 'pickup': 39748, 'truck': 25476, 'other': 17239, 'coupe': 15452, 'hatchback': 14747, 'wagon': 9678, 'van': 8135, 'minivan': 5657, 'convertible': 5641, 'offroad': 409, 'bus': 256}\n",
      "Invalid Values: {}\n",
      "Null Values: 76\n",
      "Validation Passed: False\n",
      "Case Standardized: True\n"
     ]
    }
   ],
   "source": [
    "# 6 \n",
    "from DataCleaning.data_type import validate_type_values\n",
    "df, summary = validate_type_values(df, standardize_case=True)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 295,921\n",
      "Filtered Rows: 294,000\n",
      "Dropped Rows: 1,921\n",
      "Drop Percentage: 0.65\n",
      "Valid Manufacturers Count: 72\n",
      "Found Manufacturers Count: 61\n",
      "Invalid Manufacturers: {'crosley': np.int64(1215), 'austin': np.int64(657), 'harley-davidson': np.int64(38), 'harley': np.int64(6), 'desoto': np.int64(5)}\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "# Usage\n",
    "\n",
    "from DataCleaning.data_manufacturers import  validate_manufacturers \n",
    "df, summary = validate_manufacturers(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 294,000\n",
      "Final Rows: 294,000\n",
      "Rows Dropped: 0\n",
      "Invalid Values: 0\n",
      "Valid Colors: ['white', 'black', 'silver', 'blue', 'red', 'grey', 'green', 'brown', 'custom', 'orange', 'yellow', 'purple']\n"
     ]
    }
   ],
   "source": [
    "# 8 \n",
    "from DataCleaning.data_paint_color import validate_paint_color\n",
    "df, summary = validate_paint_color(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 294,000\n",
      "Final Rows: 294,000\n",
      "Rows Dropped: 0\n",
      "Invalid Values: 0\n",
      "Valid States: ['ca', 'fl', 'tx', 'ny', 'oh', 'mi', 'pa', 'or', 'wa', 'nc', 'wi', 'tn', 'co', 'il', 'id', 'va', 'nj', 'az', 'ma', 'mn', 'ia', 'ga', 'ks', 'mt', 'in', 'ok', 'sc', 'ct', 'md', 'al', 'ky', 'mo', 'ak', 'nm', 'nv', 'ar', 'dc', 'nh', 'la', 'me', 'vt', 'hi', 'ri', 'ut', 'sd', 'wv', 'ms', 'ne', 'de', 'wy', 'nd']\n"
     ]
    }
   ],
   "source": [
    "# 9 \n",
    "from DataCleaning.data_state import validate_state\n",
    "df, summary = validate_state(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 294,000\n",
      "Final Rows: 293,355\n",
      "Rows Dropped: 645\n",
      "Min Count Threshold: 10\n",
      "Models Kept: 808\n",
      "Models Dropped: 112\n",
      "Infrequent Model Rows: 645\n"
     ]
    }
   ],
   "source": [
    "# 10 model \n",
    "from DataCleaning.data_model import validate_model_frequency\n",
    "\n",
    "df_clean, summary = validate_model_frequency(df, min_count=10)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 294,000\n",
      "Final Rows: 294,000\n",
      "Rows Dropped: 0\n",
      "Invalid Values: 0\n",
      "Valid Drives: ['4wd', 'fwd', 'rwd']\n",
      "Value Counts: {'4wd': 133495, 'fwd': 114880, 'rwd': 45625}\n"
     ]
    }
   ],
   "source": [
    "# 11 Drive  \n",
    "from DataCleaning.data_drive import validate_drive_values\n",
    "df, summary = validate_drive_values(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 294,000\n",
      "Final Rows: 294,000\n",
      "Rows Dropped: 0\n",
      "Invalid Values: 0\n",
      "Min Miles: 0\n",
      "Max Miles: 500,000\n"
     ]
    }
   ],
   "source": [
    "# 13\n",
    "from DataCleaning.data_odometer import validate_odometer \n",
    "\n",
    "df, summary = validate_odometer(df, min_miles=0, max_miles=500000)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "Original Rows: 294,000\n",
      "Final Rows: 293,943\n",
      "Rows Dropped: 57\n",
      "Invalid Coordinates: 57\n",
      "Lat Bounds: 18.0 - 72.0\n",
      "Long Bounds: -180.0 - -66.0\n"
     ]
    }
   ],
   "source": [
    "from DataCleaning.data_lat_long import validate_usa_coordinates\n",
    "df, summary = validate_usa_coordinates(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "price            0\n",
       "year             0\n",
       "manufacturer     0\n",
       "model            0\n",
       "fuel             0\n",
       "odometer         0\n",
       "title_status     0\n",
       "transmission     0\n",
       "drive            0\n",
       "type             0\n",
       "paint_color      0\n",
       "description      0\n",
       "state            0\n",
       "lat              0\n",
       "long             0\n",
       "census_region    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deal_Predection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
