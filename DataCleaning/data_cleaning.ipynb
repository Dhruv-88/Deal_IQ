{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "from utility.print_summary import print_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_PROJECT_ID=os.getenv('PROJECT_ID')\n",
    "GCS_BUCKET_NAME=os.getenv('BUCKET_NAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cloud.gcs_storage_operations:GCS Data client initialized for project: dealiq-465722\n",
      "INFO:cloud.gcs_storage_operations:Parquet read: dealiq_1/raw_data.parquet (426880 rows, 26 columns)\n",
      "/Users/dhruvpatel/miniconda3/envs/Deal_Predection/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:cloud.gcs_storage_operations:GCS Data client initialized for project: dealiq-465722\n",
      "INFO:cloud.gcs_storage_operations:CSV read: dealiq_1/manufacturers_list.csv (88 rows, 1 columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully loaded 88 manufacturers from GCS\n",
      "Summary\n",
      "=======\n",
      "Original Columns: 26\n",
      "Final Columns: 16\n",
      "Dropped Columns: ['url', 'image_url', 'county', 'VIN', 'size', 'condition', 'posting_date', 'cylinders', 'region', 'region_url']\n",
      "Missing Columns: []\n",
      "Columns Dropped Count: 10\n",
      "Columns Remaining: ['id', 'price', 'year', 'manufacturer', 'model', 'fuel', 'odometer', 'title_status', 'transmission', 'drive', 'type', 'paint_color', 'description', 'state', 'lat', 'long']\n",
      "Summary\n",
      "=======\n",
      "Original Rows: 426,880\n",
      "Final Rows: 403,254\n",
      "Dropped Rows: 23,626\n",
      "Drop Percentage: 5.53\n",
      "Columns With Few Missing: ['year', 'description', 'fuel', 'odometer', 'lat', 'long', 'transmission', 'model', 'manufacturer']\n",
      "Missing Columns: []\n",
      "Missing Counts Before: {'year': np.int64(78), 'description': np.int64(70), 'fuel': np.int64(3013), 'odometer': np.int64(4400), 'lat': np.int64(6549), 'long': np.int64(6549), 'transmission': np.int64(2556), 'model': np.int64(5277), 'manufacturer': np.int64(4084)}\n",
      "Total Missing Values: 32576\n",
      "Summary\n",
      "=======\n",
      "Column Name: title_status\n",
      "Fill Value: missing\n",
      "Missing Before: 6978\n",
      "Missing After: 0\n",
      "Values Filled: 6978\n",
      "Total Rows: 403,254\n",
      "Summary\n",
      "=======\n",
      "Column Name: transmission\n",
      "Fill Value: automatic\n",
      "Missing Before: 0\n",
      "Missing After: 0\n",
      "Values Filled: 0\n",
      "Total Rows: 403,254\n",
      "Summary\n",
      "=======\n",
      "Total Rows: 403,254\n",
      "Original Unique Values: 3\n",
      "New Unique Values: 2\n",
      "Original Value Counts: {'automatic': 318647, 'other': 61430, 'manual': 23177}\n",
      "New Value Counts: {'automatic': 380077, 'manual': 23177}\n",
      "Converted To Automatic: 380,077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cloud.gcs_storage_operations:GCS Data client initialized for project: dealiq-465722\n",
      "ERROR:cloud.gcs_storage_operations:Error reading CSV: 404 GET https://storage.googleapis.com/download/storage/v1/b/dealiq_1/o/%2FUsers%2Fdhruvpatel%2FDesktop%2Fprojects%2FDealPredection%2Fdata%2Fmodels_with_drive.csv?alt=media: No such object: dealiq_1//Users/dhruvpatel/Desktop/projects/DealPredection/data/models_with_drive.csv: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully loaded reference data from GCS: /Users/dhruvpatel/Desktop/projects/DealPredection/data/models_with_drive.csv\n",
      "Warning: Could not load reference data from GCS: 'NoneType' object has no attribute 'shape'\n",
      "Using fallback model-drive mappings...\n",
      "Summary\n",
      "=======\n",
      "Total Rows: 403,254\n",
      "Missing Before: 0\n",
      "Missing After: 0\n",
      "Values Filled: 0\n",
      "Fallback Used: True\n",
      "Error: 'NoneType' object has no attribute 'shape'\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'remove_numerical_models' from 'DataCleaning.data_model' (/Users/dhruvpatel/Desktop/projects/DealPredection/DataCleaning/../DataCleaning/data_model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDataCleaning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_cleaning_main\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m main_data_cleaning_pipeline \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmain_data_cleaning_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/DealPredection/DataCleaning/../DataCleaning/data_cleaning_main.py:63\u001b[39m, in \u001b[36mmain_data_cleaning_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     60\u001b[39m print_summary(summary)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Step 11: Remove numerical models (Stage 1 of model cleaning)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDataCleaning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m remove_numerical_models\n\u001b[32m     64\u001b[39m df, summary = remove_numerical_models(df)\n\u001b[32m     65\u001b[39m print_summary(summary)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'remove_numerical_models' from 'DataCleaning.data_model' (/Users/dhruvpatel/Desktop/projects/DealPredection/DataCleaning/../DataCleaning/data_model.py)"
     ]
    }
   ],
   "source": [
    "from DataCleaning.data_cleaning_main import main_data_cleaning_pipeline \n",
    "\n",
    "main_data_cleaning_pipeline()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# standardizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  standardization  and extracting info from model and description.\n",
    "from DataCleaning.data_model import process_car_dataset\n",
    "\n",
    "df=process_car_dataset(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping  unnecessory columns\n",
    "from DataCleaning.data_cleaning import drop_unnecessary_columns , drop_rows_with_few_missing_values\n",
    "\n",
    "df, summary = drop_unnecessary_columns(df) \n",
    "print_summary(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows due to high NAs \n",
    "\n",
    "df, summary = df_cleaned, summary = drop_rows_with_few_missing_values(df) \n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values in title status with 'missing' \n",
    "from DataCleaning.data_title_status import fill_missing_values \n",
    "\n",
    "df,summary = fill_missing_values(df) \n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCleaning.data_transmission import fill_missing_values_transmission, convert_transmission_to_automatic \n",
    "\n",
    "\n",
    "df,summary = fill_missing_values_transmission(df) \n",
    "print_summary(summary)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, summary = convert_transmission_to_automatic(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drive column cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardasition \n",
    "from DataCleaning.data_drive import clean_drive_column\n",
    "df,summary=clean_drive_column(df, 'drive')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values from research : (na values)\n",
    "from DataCleaning.data_drive import fill_missing_drive_from_reference\n",
    "\n",
    "\n",
    "df,summary = fill_missing_drive_from_reference(df,\n",
    "                                       reference_file='/Users/dhruvpatel/Desktop/projects/DealPredection/data/models_with_drive.csv'\n",
    "                                                 )\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "\n",
    "Clean in stages:\n",
    "* Stage 1: Remove obvious junk (numbers, too short, too long)\n",
    "* Stage 2: Extract core model from complex strings\n",
    "* Stage 3: Standardize spelling and format\n",
    "* Stage 4: Apply manufacturer-specific rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 : Remove obvious junk (only numbers, too short, too long)\n",
    "\n",
    "from DataCleaning.data_model import remove_numerical_models\n",
    "\n",
    "df,summary =remove_numerical_models(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manufacturer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCleaning.data_model import clean_models_with_list_optimized\n",
    " \n",
    "df,summary = clean_models_with_list_optimized(df)  \n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean model \n",
    "from DataCleaning.data_model import filter_by_value_counts\n",
    "\n",
    "df = filter_by_value_counts(df, 'model', min_count=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCleaning.data_type import drop_na_drive_type  \n",
    "\n",
    "df, summary = drop_na_drive_type(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and standardasition  (type) \n",
    "from DataCleaning.data_type import replace_values \n",
    "df, summary =replace_values(df, 'type', {'mini van': 'minivan', 'mini-van': 'minivan'})\n",
    "print_summary(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values based on data present. \n",
    "# First, let's see what we're working with\n",
    "\n",
    "from DataCleaning.data_type import fill_type_from_model\n",
    "\n",
    "df, summary = fill_type_from_model(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally drop type nulls \n",
    "from DataCleaning.data_type import drop_na_type\n",
    "\n",
    "df_clean, summary =drop_na_type(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute drive 1 ( based on cross tab type )\n",
    "\n",
    "from DataCleaning.data_drive import impute_drive_from_type\n",
    "\n",
    "df, summary = impute_drive_from_type(df)\n",
    "print_summary(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manufacturer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCleaning.data_manufacturers import standardize_manufacturer \n",
    "\n",
    "df, summary =standardize_manufacturer(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paint Color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCleaning.data_paint_color import fill_paint_color_nulls \n",
    "\n",
    "# Usage\n",
    "df, summary = fill_paint_color_nulls(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# census_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  DataCleaning.data_census_region import add_census_divisions_abbrev , validate_regions\n",
    "\n",
    "# Usage\n",
    "df, summary = add_census_divisions_abbrev(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCleaning.data_price import clean_price_data \n",
    "# Usage example:\n",
    "df, summary = clean_price_data(df, 'price')\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCleaning.data_fuel import  convert_fuel_to_gas\n",
    "\n",
    "\n",
    "df,summary = convert_fuel_to_gas(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# odometer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions\n",
    "from DataCleaning.data_odometer import process_odometer_column\n",
    "\n",
    "\n",
    "\n",
    "# Clean the data (recommended approach)\n",
    "df, summary = process_odometer_column(df, 'odometer')\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# validation columns \n",
    "\n",
    "1. census_region ✅ \n",
    "2. drive ✅\n",
    "3. fuel ✅\n",
    "4. lat  \n",
    "5. long\n",
    "6. manufacturer ✅ \n",
    "7. model ✅ \n",
    "8.  ✅\n",
    "9. paint_color ✅\n",
    "10. price ✅\n",
    "11. state ✅\n",
    "12. title_status ✅\n",
    "13. transmission ✅\n",
    "14. type ✅\n",
    "15. year ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 census_region \n",
    "df, summary = validate_regions(df) \n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 \n",
    "from DataCleaning.data_year import validate_years\n",
    "# Usage\n",
    "df, summary = validate_years(df, year_column='year', min_year=1990)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "# transmission column \n",
    "\n",
    "from DataCleaning.data_transmission import  validate_transmission_values \n",
    "\n",
    "df, validation_summary = validate_transmission_values(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 \n",
    "from DataCleaning.data_fuel import validate_fuel_values\n",
    "df , summary = validate_fuel_values(df) \n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 \n",
    "from DataCleaning.data_title_status import validate_title_status_values \n",
    "\n",
    "df, summary = validate_title_status_values(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 \n",
    "from DataCleaning.data_type import validate_type_values\n",
    "df, summary = validate_type_values(df, standardize_case=True)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "# Usage\n",
    "\n",
    "from DataCleaning.data_manufacturers import  validate_manufacturers \n",
    "df, summary = validate_manufacturers(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 \n",
    "from DataCleaning.data_paint_color import validate_paint_color\n",
    "df, summary = validate_paint_color(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 \n",
    "from DataCleaning.data_state import validate_state\n",
    "df, summary = validate_state(df)\n",
    "\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 model \n",
    "from DataCleaning.data_model import validate_model_frequency\n",
    "\n",
    "df_clean, summary = validate_model_frequency(df, min_count=10)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 Drive  \n",
    "from DataCleaning.data_drive import validate_drive_values\n",
    "df, summary = validate_drive_values(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13\n",
    "from DataCleaning.data_odometer import validate_odometer \n",
    "\n",
    "df, summary = validate_odometer(df, min_miles=0, max_miles=500000)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCleaning.data_lat_long import validate_usa_coordinates\n",
    "df, summary = validate_usa_coordinates(df)\n",
    "print_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deal_Predection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
